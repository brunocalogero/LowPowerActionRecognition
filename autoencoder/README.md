This will hold the documentation for all research made on auto-encoders, use it as a means to keep track of the work you have done
and, eventually as something that allows people to understand what you have been up to.

Use this to also keep track of all the resources that you have used to come up with your solution.

As a starting point you can play with the MNIST DVS data set / or the normal MNIST and create your small autoencoder:
https://www.jeremyjordan.me/autoencoders/ (this is a good starting point)

I would also explore and gather the best possible understanding as to where this auto-encoder / compressor/decompressor
will be integrated in the overall system, benefits of using one over the other and most importantly, benchmarks.
Don't be scared to send personal emails to Yiannis asking questions and what not to gather a better understanding of what the expectations are here.


Always keep in mind - the title of our project is Low Power Action recognition - keep in mind how compression is helping achieve the objective of the project, (in this case auto-encoding would mimic the easier file transfer from the DVS camera to the portable system in an efficient way). Everytime you see that something from this autoencoder can help achieve our objectives right it down and pivot towards that objective.
