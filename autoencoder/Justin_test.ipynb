{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "#from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whole N-MNIST Dataset\n",
    "def load_NMNIST(path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    xs_train = []\n",
    "    ys_train = []\n",
    "    xs_test = []\n",
    "    ys_test = []\n",
    "\n",
    "    for class_index in range(0, 10):\n",
    "        for (root, dirs, dat_files) in os.walk('{0}/n_Train_3/{1}'.format(path, str(class_index))):\n",
    "            for file in dat_files:\n",
    "                single_X = np.fromfile('{0}/n_Train_3/{1}/{2}'.format(path, str(class_index), file), dtype=np.int32)\n",
    "                xs_train.append(single_X)\n",
    "                ys_train.append(class_index)\n",
    "\n",
    "        for (root, dirs, dat_files) in os.walk('{0}/n_Test_3/{1}'.format(path, str(class_index))):\n",
    "            for file in dat_files:\n",
    "                xs_test.append(np.fromfile('{0}/n_Test_3/{1}/{2}'.format(path, str(class_index), file), dtype=np.int32))\n",
    "                ys_test.append(class_index)\n",
    "\n",
    "    Xtr = np.array(xs_train)\n",
    "    Ytr = np.array(ys_train)\n",
    "    Xte = np.array(xs_test)\n",
    "    Yte = np.array(ys_test)\n",
    "\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 2312)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 2312)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "dataset_class_path = 'M:/LowPowerActionRecognition/CNN/NMNIST/datasets'\n",
    "x_train_1, y_train, x_test_1, y_test = load_NMNIST(dataset_class_path)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', x_train_1.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test_1.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "# 34 x 34 x 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "-15\n"
     ]
    }
   ],
   "source": [
    "# Test to see the maxima and minima of the dataset to flatten it\n",
    "maxi = x_train_1[0][0]\n",
    "mini = x_train_1[0][0]\n",
    "for i in range (0, len(x_train_1)):\n",
    "    if (max(x_train_1[i])>maxi):\n",
    "        maxi = max(x_train_1[i])\n",
    "    if (min(x_train_1[i])<mini):\n",
    "        mini = min(x_train_1[i])\n",
    "print(maxi)\n",
    "print(mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value: 0.8666667\n",
      "min value: -1.0\n"
     ]
    }
   ],
   "source": [
    "# Flatten the dataset from range -1 to 1. Since the maxima and minima lies btw 15 so we divide it by 15.\n",
    "x_train = (x_train_1.astype('float32'))/15\n",
    "x_test = (x_test_1.astype('float32'))/15\n",
    "\n",
    "print(\"max value:\", np.max(x_train))\n",
    "print(\"min value:\", np.min(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def plot_autoencoder_outputs(encoder, n, dims):\\n    #decoded_imgs = enconder.predict(x_test)\\n    x_test_encoded = vae.predict(x_test, batch_size = batch_size)\\n    # number of example digits to show\\n    n = 5\\n    plt.figure(figsize=(20, 9))\\n    for i in range(n):\\n        # plot original image\\n        ax = plt.subplot(2, n, i + 1)\\n        plt.imshow(x_test[i].reshape(*dims))\\n        #plt.gray()\\n        ax.get_xaxis().set_visible(False)\\n        ax.get_yaxis().set_visible(False)\\n        if i == n/2:\\n            ax.set_title(\\'Original Images\\')\\n\\n        # plot reconstruction \\n        ax = plt.subplot(2, n, i + 1 + n)\\n        plt.imshow(x_test_encoded[i].reshape(*dims))\\n        #plt.gray()\\n        ax.get_xaxis().set_visible(False)\\n        ax.get_yaxis().set_visible(False)\\n        if i == n/2:\\n            ax.set_title(\\'Reconstructed Images\\')\\n    plt.show()\\n\\ndef plot_loss(history):\\n    historydf = pd.DataFrame(history.history, index=history.epoch)\\n    plt.figure(figsize=(8, 6))\\n    historydf.plot(ylim=(0, historydf.values.max()))\\n    plt.title(\\'Loss: %.3f\\' % history.history[\\'loss\\'][-1])\\n    \\ndef plot_compare_histories(history_list, name_list, plot_accuracy=True):\\n    dflist = []\\n    min_epoch = len(history_list[0].epoch)\\n    losses = []\\n    for history in history_list:\\n        h = {key: val for key, val in history.history.items() if not key.startswith(\\'val_\\')}\\n        dflist.append(pd.DataFrame(h, index=history.epoch))\\n        min_epoch = min(min_epoch, len(history.epoch))\\n        losses.append(h[\\'loss\\'][-1])\\n\\n    historydf = pd.concat(dflist, axis=1)\\n\\n    metrics = dflist[0].columns\\n    idx = pd.MultiIndex.from_product([name_list, metrics], names=[\\'model\\', \\'metric\\'])\\n    historydf.columns = idx\\n    \\n    plt.figure(figsize=(6, 8))\\n\\n    ax = plt.subplot(211)\\n    historydf.xs(\\'loss\\', axis=1, level=\\'metric\\').plot(ylim=(0,1), ax=ax)\\n    plt.title(\"Training Loss: \" + \\' vs \\'.join([str(round(x, 3)) for x in losses]))\\n    \\n    if plot_accuracy:\\n        ax = plt.subplot(212)\\n        historydf.xs(\\'acc\\', axis=1, level=\\'metric\\').plot(ylim=(0,1), ax=ax)\\n        plt.title(\"Accuracy\")\\n        plt.xlabel(\"Epochs\")\\n    \\n    plt.xlim(0, min_epoch-1)\\n    plt.tight_layout()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def plot_autoencoder_outputs(encoder, n, dims):\n",
    "    #decoded_imgs = enconder.predict(x_test)\n",
    "    x_test_encoded = vae.predict(x_test, batch_size = batch_size)\n",
    "    # number of example digits to show\n",
    "    n = 5\n",
    "    plt.figure(figsize=(20, 9))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(x_test_encoded[i].reshape(*dims))\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, historydf.values.max()))\n",
    "    plt.title('Loss: %.3f' % history.history['loss'][-1])\n",
    "    \n",
    "def plot_compare_histories(history_list, name_list, plot_accuracy=True):\n",
    "    dflist = []\n",
    "    min_epoch = len(history_list[0].epoch)\n",
    "    losses = []\n",
    "    for history in history_list:\n",
    "        h = {key: val for key, val in history.history.items() if not key.startswith('val_')}\n",
    "        dflist.append(pd.DataFrame(h, index=history.epoch))\n",
    "        min_epoch = min(min_epoch, len(history.epoch))\n",
    "        losses.append(h['loss'][-1])\n",
    "\n",
    "    historydf = pd.concat(dflist, axis=1)\n",
    "\n",
    "    metrics = dflist[0].columns\n",
    "    idx = pd.MultiIndex.from_product([name_list, metrics], names=['model', 'metric'])\n",
    "    historydf.columns = idx\n",
    "    \n",
    "    plt.figure(figsize=(6, 8))\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    historydf.xs('loss', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "    plt.title(\"Training Loss: \" + ' vs '.join([str(round(x, 3)) for x in losses]))\n",
    "    \n",
    "    if plot_accuracy:\n",
    "        ax = plt.subplot(212)\n",
    "        historydf.xs('acc', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.xlim(0, min_epoch-1)\n",
    "    plt.tight_layout()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "x_train[x_train>0]=1\n",
    "x_train[x_train<0]=-1\n",
    "x_test[x_test>0]=1\n",
    "x_test[x_test<0]=-1\n",
    "#print(x_train.shape)\n",
    "print(np.max(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 2312)\n",
      "(48000, 2312)\n"
     ]
    }
   ],
   "source": [
    "x_train_new = shuffle(x_train)\n",
    "\n",
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 12000\n",
    "mask = list(range(num_training))\n",
    "val_data = x_train_new[:12000]\n",
    "x_train_new = x_train_new[12000:60000]\n",
    "\n",
    "print(val_data.shape)\n",
    "print(x_train_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_std=1\n",
    "\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "#returns random value of z with the gives mean and variance\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.0, stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma/2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "#batch_size - number of training examples \n",
    "#that are used at the same time to train the NN\n",
    "#latent_dim - defines the dimentionality of the latent space\n",
    "#2D latent space in this case\n",
    "input_shape = (2312, )\n",
    "intermediate_dim_1 = 64\n",
    "intermediate_dim_2 = 16\n",
    "intermediate_dim_3 = 32\n",
    "intermediate_dim_4 = 16\n",
    "intermediate_dim_5 = 8\n",
    "batch_size = 64\n",
    "latent_dim = 2\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input') #2312\n",
    "x = Dense(intermediate_dim_1, activation='tanh')(inputs)\n",
    "x = Dense(intermediate_dim_2, activation='tanh')(x)\n",
    "#x = Dense(intermediate_dim_3, activation='tanh')(x)\n",
    "#x = Dense(intermediate_dim_4, activation='tanh')(x)\n",
    "#x = Dense(intermediate_dim_5, activation='tanh')(x)\n",
    "# x = Dense(intermediate_dim_2, activation='relu')(inputs)\n",
    "# x = Dense(intermediate_dim_3, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 2312)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           148032      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1040        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 149,140\n",
      "Trainable params: 149,140\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "#x = Dense(intermediate_dim_5, activation='tanh')(latent_inputs)\n",
    "#x = Dense(intermediate_dim_4, activation='tanh')(latent_inputs)\n",
    "#x = Dense(intermediate_dim_3, activation='tanh')(x)\n",
    "x = Dense(intermediate_dim_2, activation='tanh')(latent_inputs)\n",
    "x = Dense(intermediate_dim_1, activation='tanh')(x)\n",
    "# x = Dense(intermediate_dim_3, activation='relu')(latent_inputs)\n",
    "# x = Dense(intermediate_dim_2, activation='relu')(x)\n",
    "outputs = Dense(2312, activation='tanh')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2312)              150280    \n",
      "=================================================================\n",
      "Total params: 151,416\n",
      "Trainable params: 151,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "vae_test=Model(inputs, outputs, name='vae_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 2312)              0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 149140    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 2312)              151416    \n",
      "=================================================================\n",
      "Total params: 300,556\n",
      "Trainable params: 300,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 2312)              0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 149140    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 2312)              151416    \n",
      "=================================================================\n",
      "Total params: 300,556\n",
      "Trainable params: 300,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compute VAE loss\n",
    "xent_loss = 2312 * binary_crossentropy(inputs, outputs)\n",
    "#xent_loss = binary_crossentropy(inputs, outputs)\n",
    "\n",
    "kl_loss = -0.5*K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss =abs(K.mean(xent_loss + kl_loss))\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae_test.compile(optimizer='adam',loss='binary_crossentropy', metrics=[metrics.categorical_accuracy])\n",
    "vae.summary()\n",
    "vae_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\n\\nx_train2, x_test2, y_train2, y_test2 = train_test_split(x_train, y_train, test_size=0.2, shuffle = True)\\nprint(x_train2.shape)\\nprint(x_test2.shape)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_train, y_train, test_size=0.2, shuffle = True)\n",
    "print(x_train2.shape)\n",
    "print(x_test2.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2019-01-16 20:17:13.087625\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 46.9060"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [32,2] vs. [64,2]\n\t [[{{node encoder/z/mul}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](encoder/z/Exp, encoder/z/random_normal/RandomStandardNormal)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3763dc8cdf54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#validation_data= (val_data, None),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m#validation_steps=64,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#steps_per_epoch=64,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mM:\\Anaconda\\envs\\cs231n\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [32,2] vs. [64,2]\n\t [[{{node encoder/z/mul}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](encoder/z/Exp, encoder/z/random_normal/RandomStandardNormal)]]"
     ]
    }
   ],
   "source": [
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "\n",
    "# changes to epochs, validation_split and batch_size\n",
    "vae.fit(x_train,    \n",
    "        shuffle = False,\n",
    "        epochs= 10,\n",
    "        #validation_data= (val_data, None),\n",
    "        validation_split= 0.2,\n",
    "        batch_size= 64,\n",
    "        #validation_steps=64,\n",
    "        #steps_per_epoch=64,\n",
    "        )\n",
    "\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=100,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n",
    "    # Arguments:\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    print(z_mean)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=batch_size,\n",
    "                 model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(10, 4.5))\n",
    "for i in range(n):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train_1[i].reshape(34, 68))\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Original Images')\n",
    "\n",
    "    # plot noisy image \n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_encoded[i].reshape(34, 68))\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == n/2:\n",
    "        ax.set_title('Noisy Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = vae.predict(x_test, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test_encoded[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(x_test_encoded, 5, (34, 68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_test.set_weights(vae.get_weights())\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "shuffle(x_test)\n",
    "\n",
    "score = vae_test.evaluate(x_test, x_test, verbose=1, batch_size=100)\n",
    "#score = vae.evaluate(x_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a pre_train SVM model after the decoder then compare it with a normal SVM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
