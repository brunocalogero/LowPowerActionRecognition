{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with normal data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "\n",
    "x_train = np.load('x_train_1.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "x_test  = np.load('x_test_1.npy')\n",
    "y_test  = np.load('x_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (60000, 2312)\n",
      "Training labels shape: (60000,)\n",
      "Testing dataset shape: (10000, 2312)\n",
      "Training labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Check for dimensions\n",
    "print(\"Training dataset shape:\", x_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing dataset shape:\", x_test.shape)\n",
    "print(\"Training labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_training = 60000\\nnum_dev = 60000\\n\\n# We will also make a development set, which is a small subset of\\n# the training set.\\nmask = np.random.choice(num_training, num_dev, replace=False)\\nX_dev = x_train[mask]\\nY_dev = y_train[mask]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"num_training = 60000\n",
    "num_dev = 60000\n",
    "\n",
    "# We will also make a development set, which is a small subset of\n",
    "# the training set.\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = x_train[mask]\n",
    "Y_dev = y_train[mask]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Check input_data dimensions\\nprint(X_dev.shape)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Check input_data dimensions\n",
    "print(X_dev.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#SVM\\n#classifier = svm.SVC(C=5,kernel='rbf',gamma=0.01,cache_size=8000,probability=False)\\nclassifier = svm.SVC(C=5,kernel='rbf',gamma=0.0005,cache_size=8000,probability=False)\\n\\nstart_time = dt.datetime.now()\\nprint('Start learning at {}'.format(str(start_time)))\\n\\nclassifier.fit(X_dev, Y_dev)\\n\\nend_time = dt.datetime.now() \\nprint('Stop learning {}'.format(str(end_time)))\\nelapsed_time= end_time - start_time\\nprint('Elapsed learning {}'.format(str(elapsed_time))) \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#SVM\n",
    "#classifier = svm.SVC(C=5,kernel='rbf',gamma=0.01,cache_size=8000,probability=False)\n",
    "classifier = svm.SVC(C=5,kernel='rbf',gamma=0.0005,cache_size=8000,probability=False)\n",
    "\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "\n",
    "classifier.fit(X_dev, Y_dev)\n",
    "\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time))) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\Anaconda3\\envs\\AMLSassignment\\lib\\site-packages\\sklearn\\base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Open saved model\n",
    "# load the model from disk\n",
    "import pickle\n",
    "\n",
    "print(\"Loading the model:\")\n",
    "\n",
    "filename = 'Model_with_normal_data.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'),encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=5, cache_size=8000, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0005, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.98      0.99      0.99      1135\n",
      "           2       0.96      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.97      1010\n",
      "           4       0.97      0.98      0.97       982\n",
      "           5       0.97      0.96      0.96       892\n",
      "           6       0.98      0.97      0.97       958\n",
      "           7       0.98      0.96      0.97      1028\n",
      "           8       0.96      0.95      0.96       974\n",
      "           9       0.97      0.95      0.96      1009\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 966    0    1    2    0    2    2    3    3    1]\n",
      " [   0 1126    3    2    0    0    2    1    1    0]\n",
      " [   5    2 1004    5    2    0    1    6    7    0]\n",
      " [   1    0    7  981    0    7    1    3    7    3]\n",
      " [   0    2    1    0  960    0    5    1    4    9]\n",
      " [   2    1    0   13    1  858    8    2    5    2]\n",
      " [   9    4    1    0    5    7  931    0    1    0]\n",
      " [   0   10   16    2    3    1    1  985    2    8]\n",
      " [   4    0   13   10    5   10    1    3  926    2]\n",
      " [   6    6    1    6   12    3    0    4    9  962]]\n",
      "Accuracy=0.9699\n"
     ]
    }
   ],
   "source": [
    "# Now predict the value of the test\n",
    "expected = y_test\n",
    "\n",
    "predicted = loaded_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (loaded_model, metrics.classification_report(expected, predicted)))\n",
    "      \n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "# plot_confusion_matrix(cm)\n",
    "\n",
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
