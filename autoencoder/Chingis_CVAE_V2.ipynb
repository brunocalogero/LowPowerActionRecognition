{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Input, Dense, Conv2D, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "#from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import glob\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "#tfe = tf.contrib.eager\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(encoder, n, dims):\n",
    "    #decoded_imgs = enconder.predict(x_test)\n",
    "    x_test_encoded = vae.predict(x_test, batch_size = batch_size)\n",
    "    # number of example digits to show\n",
    "    n = 5\n",
    "    plt.figure(figsize=(20, 9))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(x_test_encoded[i].reshape(*dims))\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, historydf.values.max()))\n",
    "    plt.title('Loss: %.3f' % history.history['loss'][-1])\n",
    "    \n",
    "def plot_compare_histories(history_list, name_list, plot_accuracy=True):\n",
    "    dflist = []\n",
    "    min_epoch = len(history_list[0].epoch)\n",
    "    losses = []\n",
    "    for history in history_list:\n",
    "        h = {key: val for key, val in history.history.items() if not key.startswith('val_')}\n",
    "        dflist.append(pd.DataFrame(h, index=history.epoch))\n",
    "        min_epoch = min(min_epoch, len(history.epoch))\n",
    "        losses.append(h['loss'][-1])\n",
    "\n",
    "    historydf = pd.concat(dflist, axis=1)\n",
    "\n",
    "    metrics = dflist[0].columns\n",
    "    idx = pd.MultiIndex.from_product([name_list, metrics], names=['model', 'metric'])\n",
    "    historydf.columns = idx\n",
    "    \n",
    "    plt.figure(figsize=(6, 8))\n",
    "\n",
    "    ax = plt.subplot(211)\n",
    "    historydf.xs('loss', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "    plt.title(\"Training Loss: \" + ' vs '.join([str(round(x, 3)) for x in losses]))\n",
    "    \n",
    "    if plot_accuracy:\n",
    "        ax = plt.subplot(212)\n",
    "        historydf.xs('acc', axis=1, level='metric').plot(ylim=(0,1), ax=ax)\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "    \n",
    "    plt.xlim(0, min_epoch-1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whole N-MNIST Dataset\n",
    "def load_NMNIST(path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    xs_train = []\n",
    "    ys_train = []\n",
    "    xs_test = []\n",
    "    ys_test = []\n",
    "\n",
    "    for class_index in range(0, 10):\n",
    "        for (root, dirs, dat_files) in os.walk('{0}/n_Train_3/{1}'.format(path, str(class_index))):\n",
    "            for file in dat_files:\n",
    "                single_X = np.fromfile('{0}/n_Train_3/{1}/{2}'.format(path, str(class_index), file), dtype=np.int32)\n",
    "                xs_train.append(single_X)\n",
    "                ys_train.append(class_index)\n",
    "\n",
    "        for (root, dirs, dat_files) in os.walk('{0}/n_Test_3/{1}'.format(path, str(class_index))):\n",
    "            for file in dat_files:\n",
    "                xs_test.append(np.fromfile('{0}/n_Test_3/{1}/{2}'.format(path, str(class_index), file), dtype=np.int32))\n",
    "                ys_test.append(class_index)\n",
    "\n",
    "    Xtr = np.array(xs_train)\n",
    "    Xtr_reshaped = Xtr.reshape(60000, 34, 34, 2)\n",
    "    Ytr = np.array(ys_train)\n",
    "    Xte = np.array(xs_test)\n",
    "    Xte_reshaped = Xte.reshape(10000, 34, 34, 2)\n",
    "    Yte = np.array(ys_test)\n",
    "\n",
    "    return Xtr_reshaped, Ytr, Xte_reshaped, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 34, 34, 2)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 34, 34, 2)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "dataset_class_path = '/Users/ching/Desktop/Project/autoencoder_nmnist/NMNIST/datasets'\n",
    "x_train_1, y_train, x_test_1, y_test = load_NMNIST(dataset_class_path)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', x_train_1.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test_1.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "\n",
    "# 34 x 34 x 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the dataset from range -1 to 1. Since the maxima and minima lies btw 15 so we divide it by 15.\n",
    "x_train = (x_train_1.astype('float32'))\n",
    "x_test = (x_test_1.astype('float32'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[x_train!=0]+=30\n",
    "x_test[x_test!=0]+=30\n",
    "#print(x_train.shape)\n",
    "#print(max(x_train[0])) #Test the maximum value after flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train/45\n",
    "x_train[:] = [x / 45 for x in x_train]\n",
    "#x_test = x_test/45\n",
    "x_test[:] = [x / 45 for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 60000\n",
    "BATCH_SIZE = 80\n",
    "\n",
    "TEST_BUF = 10000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test).shuffle(TEST_BUF).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_std=0.01\n",
    "\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "#returns random value of z with the gives mean and variance\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.0, stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma/2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining number of kernels, strides and pooling sizes per layer\n",
    "\n",
    "kernel_1 = 8\n",
    "kernel_2 = 16\n",
    "kernel_3 = 32\n",
    "# kernel_4 = 64\n",
    "# kernel_5 = 128\n",
    "# kernel_6 = 256\n",
    "# kernel_7 = 512\n",
    "\n",
    "stride_1 = (3, 3)\n",
    "stride_2 = (2, 2)\n",
    "stride_3 = (2, 2)\n",
    "# stride_4 = (2, 2)\n",
    "# stride_5 = (2, 2)\n",
    "# stride_6 = (2, 2)\n",
    "# stride_7 = (2, 2)\n",
    "\n",
    "pool_1 = (2, 2)\n",
    "pool_2 = (2, 2)\n",
    "pool_3 = (2, 2)\n",
    "# pool_4 = (2, 2)\n",
    "# pool_5 = (2, 2)\n",
    "# pool_6 = (2, 2)\n",
    "# pool_7 = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining encoder\n",
    "\n",
    "inputs = Input(shape = x_train_1[0].shape)\n",
    "\n",
    "x = Conv2D(kernel_1, stride_1, activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling2D(pool_1, padding='same')(x)\n",
    "\n",
    "x = Conv2D(kernel_2, stride_2, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_2, padding='same')(x)\n",
    "\n",
    "x = Conv2D(kernel_3, stride_3, activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D(pool_3, padding='same')(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "#Adding 1 hidden layer\n",
    "x = Dense(16, activation='relu')(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Decoder\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "\n",
    "x = Conv2DTranspose(kernel_3, stride_3, activation='relu', padding='same')(x)\n",
    "x = UpSampling2D(pool_3, padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(kernel_2, stride_2, activation='relu', padding='same')(x)\n",
    "x = UpSampling2D(pool_2, padding='same')(x)\n",
    "\n",
    "x = Conv2DTranspose(kernel_1, stride_1, activation='relu', padding='same')(x)\n",
    "x = UpSampling2D(pool_1, padding='same')(x)\n",
    "\n",
    "outputs = Conv2DTranspose(filters=1,\n",
    "                          kernel_size=3,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          name='decoder_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='vae_cnn_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')\n",
    "vae_test=Model(inputs, outputs, name='vae_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VAE loss\n",
    "xent_loss = 2312 * binary_crossentropy(K.flatten(inputs), K.flatten(outputs))\n",
    "#xent_loss = binary_crossentropy(inputs, outputs)\n",
    "\n",
    "kl_loss = -0.5*K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss =abs(K.mean(xent_loss + kl_loss))\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae_test.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vae.summary()\n",
    "vae_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "\n",
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split= 0.2)\n",
    "\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=100,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as function of 2-dim latent vector\n",
    "    # Arguments:\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    print(z_mean)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=batch_size,\n",
    "                 model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(encoder, n, dims):\n",
    "    #decoded_imgs = enconder.predict(x_test)\n",
    "    #x_test_encoded = vae.predict(x_test, batch_size = batch_size)\n",
    "    # number of example digits to show\n",
    "    #n = 5\n",
    "    j=8000\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i in range(0, n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[j].reshape(*dims))\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Original Images')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(x_test_encoded[j].reshape(*dims))\n",
    "        #plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == n/2:\n",
    "            ax.set_title('Reconstructed Images')\n",
    "        j=j+1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = vae.predict(x_test, batch_size = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test_encoded[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(x_test_encoded, 10, (34, 68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_test.set_weights(vae.get_weights())\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "shuffle(x_test)\n",
    "\n",
    "score = vae_test.evaluate(x_test, x_test, verbose=1, batch_size=80)\n",
    "#score = vae.evaluate(x_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
