{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whole N-MNIST Dataset\n",
    "def load_NMNIST(path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    xs_train = []\n",
    "    ys_train = []\n",
    "    xs_test = []\n",
    "    ys_test = []\n",
    "\n",
    "    for class_index in range(0, 10):\n",
    "        for (root, dirs, dat_files) in os.walk('{0}/n_Train_3/{1}'.format(path, str(class_index))):\n",
    "            for file in dat_files:\n",
    "                single_X = np.fromfile('{0}/n_Train_3/{1}/{2}'.format(path, str(class_index), file), dtype=np.int32)\n",
    "                xs_train.append(single_X)\n",
    "                ys_train.append(class_index)\n",
    "\n",
    "        for (root, dirs, dat_files) in os.walk('{0}/n_Test_3/{1}'.format(path, str(class_index))):\n",
    "            for file in dat_files:\n",
    "                xs_test.append(np.fromfile('{0}/n_Test_3/{1}/{2}'.format(path, str(class_index), file), dtype=np.int32))\n",
    "                ys_test.append(class_index)\n",
    "\n",
    "    Xtr = np.array(xs_train)\n",
    "    Ytr = np.array(ys_train)\n",
    "    Xte = np.array(xs_test)\n",
    "    Yte = np.array(ys_test)\n",
    "\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class_path = '/Users/brunocalogero/Desktop/LowPowerActionRecognition/CNN/NMNIST/datasets'\n",
    "X_train, Y_train, X_test, Y_test = load_NMNIST(dataset_class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 2312)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 2312)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', Y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 34, 34, 2)\n",
      "Test data shape:  (10000, 34, 34, 2)\n"
     ]
    }
   ],
   "source": [
    "# turn X training values into (60000, 34, 34, 2)\n",
    "X_trainy = X_train.reshape(60000, 34, 34, 2)\n",
    "# turn X test values into (10000, 34, 34, 2)\n",
    "X_testy = X_test.reshape(10000, 34, 34, 2)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_trainy.shape)\n",
    "print('Test data shape: ', X_testy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x126963c88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1268fd438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quick sanity check to make sure our data looks like what we want as a 2D array, thus meaning our 34x34x2 is correct\n",
    "plt.imshow(X_train[0].reshape(34,68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (59000, 34, 34, 2)\n",
      "Test data shape:  (10000, 34, 34, 2)\n",
      "Validation data shape:  (1000, 34, 34, 2)\n"
     ]
    }
   ],
   "source": [
    "# hesitant about the shuffleness around here\n",
    "num_training = 59000\n",
    "num_validation = 1000\n",
    "num_test = 10000\n",
    "\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_trainy[mask]\n",
    "y_val = Y_train[mask]\n",
    "mask = range(num_training)\n",
    "X_trainy = X_trainy[mask]\n",
    "Y_train = Y_train[mask]\n",
    "mask = range(num_test)\n",
    "X_testy = X_testy[mask]\n",
    "Y_test = Y_test[mask]\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_trainy.shape)\n",
    "print('Test data shape: ', X_testy.shape)\n",
    "print('Validation data shape: ', X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_trainy, Y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_testy, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Dataset object at 0x14195c1d0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(sess, dset, x, scores, is_training=None):\n",
    "    \"\"\"\n",
    "    Check accuracy on a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: A TensorFlow Session that will be used to run the graph\n",
    "    - dset: A Dataset object on which to check accuracy\n",
    "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
    "    - scores: A TensorFlow Tensor representing the scores output from the\n",
    "      model; this is the Tensor we will ask TensorFlow to evaluate.\n",
    "      \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(scores, feed_dict=feed_dict)\n",
    "        y_pred = scores_np.argmax(axis=1)\n",
    "        num_samples += x_batch.shape[0]\n",
    "        num_correct += (y_pred == y_batch).sum()\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 1.8345\n",
      "Got 0 / 1000 correct (0.00%)\n",
      "\n",
      "Iteration 700, loss = 0.0004\n",
      "Got 0 / 1000 correct (0.00%)\n",
      "\n",
      "Starting epoch 1\n",
      "Iteration 1400, loss = 9.0964\n",
      "Got 0 / 1000 correct (0.00%)\n",
      "\n",
      "Starting epoch 2\n",
      "Iteration 2100, loss = 0.0009\n",
      "Got 0 / 1000 correct (0.00%)\n",
      "\n",
      "Starting epoch 3\n",
      "Iteration 2800, loss = 0.4081\n",
      "Got 0 / 1000 correct (0.00%)\n",
      "\n",
      "Iteration 3500, loss = 0.0004\n",
      "Got 0 / 1000 correct (0.00%)\n",
      "\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-fcc45c1e0840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_np\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mloss_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def model_init_fn(inputs):\n",
    "    channel_1, channel_2, channel_3, channel_4,  num_classes =  128, 64, 32, 16, 10\n",
    "    # consider using initializer for conv layers (variance scaling)\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(inputs, channel_1, (3, 3), padding='SAME', activation=tf.nn.leaky_relu)\n",
    "    bn1 = tf.layers.batch_normalization(conv1)\n",
    "    pool1 = tf.layers.max_pooling2d(bn1, 2, 2)\n",
    "    \n",
    "    # maybe add a dropout at some point here\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, channel_2, (3, 3), padding='SAME', activation=tf.nn.leaky_relu)\n",
    "    bn2 = tf.layers.batch_normalization(conv2)\n",
    "    pool2 = tf.layers.max_pooling2d(bn2, 2, 2)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(pool2, channel_3, (3, 3), padding='SAME', activation=tf.nn.leaky_relu)\n",
    "    bn3 = tf.layers.batch_normalization(conv3)\n",
    "    pool3 = tf.layers.max_pooling2d(bn3, 2, 2)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(pool3, channel_4, (3, 3), padding='SAME', activation=tf.nn.leaky_relu)\n",
    "    bn4 = tf.layers.batch_normalization(conv4)\n",
    "    pool4 = tf.layers.max_pooling2d(bn4, 2, 2)\n",
    "    \n",
    "    conv4_flattened = tf.layers.flatten(pool4)\n",
    "    fc = tf.layers.dense(conv4_flattened, num_classes)\n",
    "    return fc\n",
    "\n",
    "\n",
    "learning_rate = 0.01 \n",
    "tf.reset_default_graph()\n",
    "with tf.device(device):\n",
    "    x = tf.placeholder(tf.float32, [None, 34, 34, 2])\n",
    "    y = tf.placeholder(tf.int32, [None])\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    \n",
    "    scores = model_init_fn(x)\n",
    "    loss   = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "    loss   = tf.reduce_mean(loss)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss)\n",
    "        \n",
    "print_every = 2\n",
    "num_epochs = 20 \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    t = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d' % epoch)\n",
    "        for x_np, y_np in train_dset:\n",
    "            feed_dict = {x: x_np, y: y_np, is_training:1}\n",
    "            loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                check_accuracy(sess, val_dset, x, scores, is_training=is_training)\n",
    "                print()\n",
    "            t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 0.0052\n",
      "Got 1000 / 1000 correct (100.00%)\n",
      "Epoch 1, loss = 0.0080\n",
      "Got 1000 / 1000 correct (100.00%)\n",
      "Epoch 2, loss = 0.0106\n",
      "Got 1000 / 1000 correct (100.00%)\n",
      "Epoch 3, loss = 0.0002\n",
      "Got 1000 / 1000 correct (100.00%)\n",
      "Epoch 4, loss = 0.0004\n",
      "Got 1000 / 1000 correct (100.00%)\n",
      "Epoch 5, loss = 0.0071\n",
      "Got 1000 / 1000 correct (100.00%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8a5d68b1b9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0;31m# TensorFlow to evaluate loss will cause an SGD step to happen.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m           \u001b[0mloss_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d, loss = %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brunocalogero/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def model_init_fn(inputs):\n",
    "    # Network architecture: (conv -> relu -> batchnorm -> maxpool) * 2 -> FC\n",
    "    conv1 = tf.layers.conv2d(inputs, 32, (3, 3), padding='SAME', activation=tf.nn.relu)\n",
    "    bn1 = tf.layers.batch_normalization(conv1)\n",
    "    pool1 = tf.layers.max_pooling2d(bn1, 2, 2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(pool1, 64, (3, 3), padding='SAME', activation=tf.nn.relu)\n",
    "    bn2 = tf.layers.batch_normalization(conv2)\n",
    "    pool2 = tf.layers.max_pooling2d(bn2, 2, 2)\n",
    "    \n",
    "    conv2_flattened = tf.layers.flatten(pool2)\n",
    "    \n",
    "    fc = tf.layers.dense(conv2_flattened, 10)\n",
    "    \n",
    "    return fc\n",
    "\n",
    "\n",
    "learning_rate = 5e-4\n",
    "num_epoch = 10\n",
    "tf.reset_default_graph()\n",
    "with tf.device(device):\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "   \n",
    "    # Set up placeholders for the data and labels\n",
    "    x = tf.placeholder(tf.float32, [None, 34, 34, 2])\n",
    "    y = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    scores = model_init_fn(x)\n",
    "    \n",
    "    # Loss and optimization\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores))\n",
    "   \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_step = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we actually run the graph many times using the training data\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables that will live in the graph\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(num_epoch):\n",
    "      for t, (x_np, y_np) in enumerate(train_dset):\n",
    "          # Run the graph on a batch of training data; recall that asking\n",
    "          # TensorFlow to evaluate loss will cause an SGD step to happen.\n",
    "          feed_dict = {x: x_np, y: y_np, is_training:1}\n",
    "          loss_np, _ = sess.run([loss, train_step], feed_dict=feed_dict)\n",
    "\n",
    "      print('Epoch %d, loss = %.4f' % (i, loss_np))\n",
    "      check_accuracy(sess, val_dset, x, scores, is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
